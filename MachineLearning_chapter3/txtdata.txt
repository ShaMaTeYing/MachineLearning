Abstract—Due to the simplicity of their implementations, least
square support vector machine (LS-SVM) and proximal support vector machine (PSVM) have been widely used in binary
classification applications. The conventional LS-SVM and PSVM
cannot be used in regression and multiclass classification applications directly, although variants of LS-SVM and PSVM have
been proposed to handle such cases. This paper shows that both
LS-SVM and PSVM can be simplified further and a unified
learning framework of LS-SVM, PSVM, and other regularization
algorithms referred to extreme learning machine (ELM) can be
built. ELM works for the “generalized” single-hidden-layer feedforward networks (SLFNs), but the hidden layer (or called feature
mapping) in ELM need not be tuned. Such SLFNs include but are
not limited to SVM, polynomial network, and the conventional
feedforward neural networks. This paper shows the following:
1) ELM provides a unified learning platform with a widespread
type of feature mappings and can be applied in regression and
multiclass classification applications directly; 2) from the optimization method point of view, ELM has milder optimization constraints compared to LS-SVM and PSVM; 3) in theory, compared
to ELM, LS-SVM and PSVM achieve suboptimal solutions and
require higher computational complexity; and 4) in theory, ELM
can approximate any target continuous function and classify any
disjoint regions. As verified by the simulation results, ELM tends
to have better scalability and achieve similar (for regression and
binary class cases) or much better (for multiclass cases) generalization performance at much faster learning speed (up to thousands
times) than traditional SVM and LS-SVM.